# -*- coding: utf-8 -*-
"""동사사전생성.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17gxjAkiNab-G6JYQ3u7MXWUF9QbCyH8b

##count가 30개 이하인 동사들은 없애고, 구분 없이 하나의 리스트로 동사들 저장
"""

# csv 파일 읽어오기
pp = ['선익','선익2','세홍']
raw_datas = []
for i in pp:
  raw_data = pd.read_csv('{}_Remove Emoji.csv'.format(i)).drop('Unnamed: 0', axis=1)
  for ii in range(0, len(raw_data)):
    raw_datas.append(normalize('NFC',re.sub(pattern='[^\w\s]', repl='', string=str(raw_data.Review[ii]))))

morp_list = []
need_morp = ['VV','VA','VX']
#morph.lex, morph.tag

for sentence in raw_datas:
  try:
    for word in api.analyze(sentence):
      for morph in word.morphs:
        if morph.tag in need_morp:
          morp_list.append(morph.lex)
  except:
    continue

count_morph = Counter(morp_list)
morp_listt =[]
for lex, count in count_morph.items():
  if count >=30:
    morp_listt.append(lex)

#486
#real_morplist=[]
#print(real_morplist)
#for i in range(len(morp_listt)+1):
  #print(i, morp_listt[i], '                ',i+1, morp_listt[i+1])
  #ii = input('')
  #if ii != 'ㄴ':
    #real_morplist.append(morp_listt[i])

morp_dic = {}
for i in kr_list:
  morp_dic[i]=[]

for vv in real_morplist:
  vv_first = j2hcj(h2j(vv))[0]
  morp_dic[vv_first].append(vv)

mps = pd.DataFrame.from_dict(morp_dic, orient='index')
mps = mps.fillna("")
mps.to_csv('동사사전.csv', index=True)
mps
from google.colab import files
files.download('동사사전.csv')