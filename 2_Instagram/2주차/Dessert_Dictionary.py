# -*- coding: utf-8 -*-
"""ë™ì‚¬ì‚¬ì „ê³¼ ë©”ë‰´ì‚¬ì „ì„ í†µí•´ Real Reviewêµ¬ë¶„ v0.2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IN1W2KgAbNKGknF3PhvCAutYL2CUVJhX

# ì‚¬ìš©ì ê²Œì‹œê¸€ì—ì„œ ë©”ë‰´ í™•ì¸í•˜ê¸°
ì‚¬ìš©ìê°€ ì˜¬ë¦° ë¦¬ë·° ê²Œì‹œê¸€ì—ì„œ ëª…ì‚¬ë¥¼ ê°€ì ¸ì™€ ë””ì €íŠ¸ ì‚¬ì „ì— ìˆëŠ” ë””ì €íŠ¸ë¥¼ ì‚¬ìš©ìê°€ ë¨¹ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ìƒì„±
"""

import pandas as pd
import re 
import math
from unicodedata import normalize
import re
import openpyxl
from collections import Counter

# í•œê¸€ ìëª¨ë¶„ë¦¬ ëª¨ë“ˆ
!pip install jamo
from jamo import h2j, j2hcj

j2hcj(h2j('ccc'))[0]

"""###ë©”ë‰´ì‚¬ì „ê³¼ ë™ì‚¬ì‚¬ì „ ê°€ì ¸ì˜¤ê¸°"""

# ì•„ëœ°ë¦¬ì— ë©”ë‰´ ì‚¬ì „ dictionaryí˜•íƒœë¡œ ë³€í™˜
menu_df = pd.read_csv('ì•„ëœ°ë¦¬ì—ë©”ë‰´ì‚¬ì „_real.csv', encoding='utf-8')
menu_df = menu_df.fillna("")
menu_df.set_index('Unnamed: 0')

menu_df = menu_df.set_index('Unnamed: 0')
menu_df = menu_df.transpose()

menu_dic = menu_df.to_dict('list')
#''ê°’ ì œê±°í•˜ê¸°
for i in menu_dic:                              
  menu_dic[i] = list(set(menu_dic[i]))
  if '' in menu_dic[i]:
    menu_dic[i].remove('')

# ë™ì‚¬ì‚¬ì „csv ê°€ì ¸ì™€ì„œ dictionaryí˜•íƒœë¡œ êµ¬ì„±
verb_df = pd.read_csv('ë™ì‚¬ì‚¬ì „.csv', encoding='utf-8')
verb_df = verb_df.fillna("")
verb_df.set_index('Unnamed: 0')

verb_df = verb_df.set_index('Unnamed: 0')
verb_df = verb_df.transpose()

verb_dic = verb_df.to_dict('list')
#''ê°’ ì œê±°í•˜ê¸°
for i in verb_dic:                              
  verb_dic[i] = list(set(verb_dic[i]))
  if '' in verb_dic[i]:
    verb_dic[i].remove('')

"""###ì‚¬ìš©ì ê²Œì‹œê¸€ì— ë””ì €íŠ¸ê°€ 2ê°œ ì´ìƒ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""

def con_menu(post):
  #postë‚´ì— ìˆëŠ” nngë“¤ì„ ëª¨ë‘ ê°€ì§€ëŠ” nng_listìƒì„±
  nng_list=[]
  ####nn = ['NNG','NNP','NNB','NP']####
  for word in api.analyze(post):
    for morph in word.morphs:
      if morph.tag == 'NNG':
        nng_list.append(morph.lex)
  
  #nng_listë‚´ì— ë””ì €íŠ¸ ë©”ë‰´ì‚¬ì „ì— ìˆëŠ” ë‹¨ì–´ê°€ 3ê°œ ì´ìƒì´ë©´ nng_count=1, ë‹¨ì–´ê°€ í•˜ë‚˜ë„ ì—†ë‹¤ë©´ 0ìœ¼ë¡œ break
  count = 0
  nng_count = 0
  while True:
    if nng_count >= 3:
      return 1
      break
    elif count >= len(nng_list):
      return 0
      break

    nng_name = nng_list[count]
    nng_first = j2hcj(h2j(nng_name))[0]
    if nng_name in menu_dic[nng_first]:
      nng_count +=1
    count+=1

"""###ì‚¬ìš©ì ê²Œì‹œê¸€ì— ë¨¹ëŠ”ê²ƒê³¼ ê´€ë ¨ëœ ë™ì‚¬ê°€ 2ê°œ ì´ìƒ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""

def con_verb(post):
  #postë‚´ì— ìˆëŠ” ë™ì‚¬ë“¤ì„ ëª¨ë‘ ê°€ì§€ëŠ” verb_listìƒì„±
  verb_list=[]
  need_mm = ['VV','VA','VX']
  for word in api.analyze(post):
    for morph in word.morphs:
      if morph.tag in need_mm:
        verb_list.append(morph.lex)
  
  #nng_listë‚´ì— ë””ì €íŠ¸ ë©”ë‰´ì‚¬ì „ì— ìˆëŠ” ë‹¨ì–´ê°€ 2ê°œ ì´ìƒì´ë©´ nng_count=1, ë‹¨ì–´ê°€ í•˜ë‚˜ë„ ì—†ë‹¤ë©´ 0ìœ¼ë¡œ break
  count = 0
  verb_count = 0
  while True:
    if verb_count >= 2:
      return 1
      break
    elif count >= len(verb_list):
      return 0
      break

    verb = verb_list[count]
    verb_first = j2hcj(h2j(verb))[0]
    if verb in verb_dic[verb_first]:
      verb_count +=1
    count+=1

"""###Hashtagì— ìˆëŠ” ë©”ë‰´ íŒë³„í•˜ëŠ” í•¨ìˆ˜"""

ll = 'ê°œì¸ì·¨í–¥,ì‚¬ê°€ì •ì¹´í˜,ì¹´í˜ë§›ì§‘,ë”¸ê¸°ì‚¬ë‘,íœ´ë¬´ìŠ¤íƒ€ê·¸ë¨'
l_list = ll.split(",")
l_list

for word in api.analyze('ì˜¤ëŠ˜ì€ ë§ˆì¹´ë¡±ìœ¼ë¡œ ì ì‹¬ í•´ê²°í–ˆë‹¤.'):
    for morph in word.morphs:
      print(morph.lex, morph.tag)

"""#ìµœì¢…! con_verbí•¨ìˆ˜ì™€ con_menuë¥¼ í†µí•´ ì „ì²´ ê²Œì‹œê¸€ì´ ë””ì €íŠ¸ ë¦¬ë·°ì¸ì§€ êµ¬ë¶„í•˜ëŠ” í•¨ìˆ˜"""

def confirm(post):
  result = con_verb(post)*con_menu(post)
  if result == 1:
    return 1
  else:
    return 0

dessert_post = ''' á„€á…¢á„‹á…µá†«á„Œá…¥á†¨á„‹á…³á„…á…© á„…á…¢á†«á„ƒá…µá„‰á…³á„‡á…©á„ƒá…¡ á„Œá…©á‡‚á„‹á…¡á†»á„ƒá…¡ğŸ™‹â€â™€ï¸ á„‚á…©á„á…µá„ƒá…³ á„‚á…³á„á…µá†·! á„‹á…±á„á…µá„€á…¡ á„‡á…©á„á…©á†¼ á„†á…¡á†­á„‹á…µ á„€á…¡á„‚á…³á†« á„€á…©á†ºá„‹á…³á†« á„‹á…¡á„‚á…µá„Œá…µá„†á…¡á†« á„€á…¡á„‚á…³á†«á„€á…µá†¯á„‹á…µá„…á…¡á„†á…§á†« á„ƒá…³á†¯á„…á…¥á„‡á…©á„‚á…³á†«á„€á…¥á†ºá„ƒá…© á„‚á…¡á„ˆá…³á„Œá…µ á„‹á…¡á†­á„‹á…³á†« á„€á…¥á†º á„€á…¡á‡€á„ƒá…¡ğŸ˜Œá„†á…¡á†ºá„ƒá…© á„ƒá…¡á„‹á…£á†¼á„’á…¡á„€á…© á„€á…ªá„’á…¡á„€á…¦ á„ƒá…¡á†¯á„Œá…µ á„‹á…¡á†­á„‹á…¡á„‰á…¥ á„€á…«á†«á„á…¡á†­á„‹á…¡á†»á„ƒá…¡ğŸƒ á„‚á…©á†¨á„á…¡á„ƒá…© á„‹á…³á†«á„€á…³á†« á„Œá…µá†«á„’á…¡á„€á…®ğŸƒ á„‚á…¢á„‡á…®á„‚á…³á†« á„Œá…©á†· á„Œá…©á†¸á„‹á…¡á„‰á…¥ á„á…¦á„‹á…µá„á…³á„‹á…¡á„‹á…®á†º á„á…®á„á…¥á†«'''
none_post = ''' ì˜¤ëŠ˜ ì¤‘ë³µì´ë¼ëŠ” ê±¸ ì•„ì¹¨ì— ë“£ê³  ë‚®ì— ë§ˆíŠ¸ ê°”ë‹¤ ì™€ì„œ ë“œë””ì–´ ë¨¹ìŠµë‹ˆë‹¤ğŸ¤£ ë°±ìˆ™ì€ ì²˜ìŒ í–ˆëŠ”ë° ë„ˆë¬´ ë¥ë„¤ìš”...ğŸ˜–ë„ˆë¬´ ë°°ê³ íŒŒì„œ ê¸‰í•˜ê²Œ ì°ì—ˆë”ë‹ˆ ì‚¬ì§„ì´ ë§ˆìŒì— ë“¤ì§€ëŠ” ì•Šì§€ë§Œ ê·¸ë˜ë„ ì§„ì§œ ë§›ìˆì—ˆì–´ìš”ğŸ˜‹ë§ˆì§€ë§‰ì— ë‹­ì£½ê¹Œì§€ í•´ì„œ ë¨¹ì—ˆì§€ë§Œ ì£½ ì‚¬ì§„ì„ ì•ˆì°ì—ˆë„¤ìš”..ì—¬ëŸ¬ë¶„ë“¤ë„ ë§›ìˆëŠ” ìŒì‹ ë“œì‹œê³  ì•ìœ¼ë¡œ ë‚¨ì€ ì—¬ë¦„ ê±´ê°•í•˜ê²Œ ì§€ë‚´ë³´ì•„ìš”~'''
dessert_post =  normalize('NFC', re.sub(pattern='[^\w\s]', repl='', string=str(dessert_post)))
none_post =  normalize('NFC', re.sub(pattern='[^\w\s]', repl='', string=str(none_post)))

print(confirm(dessert_post))
print(confirm(none_post))





!git clone https://github.com/kakao/khaiii.git
!pip install cmake

!mkdir build

!cd build && cmake /content/khaiii

!cd /content/build/ && make all

!cd /content/build/ && make resource

!cd /content/build && make install

!cd /content/build && make package_python

!pip install /content/build/package_python

from khaiii import KhaiiiApi
api = KhaiiiApi()

kr='ã„±ã„´ã„·ã„¹ã…ã…‚ã……ã…‡ã…ˆã…Šã…‹ã…Œã…ã…ã„²ã„¸ã…‰ã…ƒã…†'
en='abcdefghijknmlopqrstuvwxyz'
kr_list = [i for i in kr]
en_list = [i for i in en]
all_list = kr_list+en_list

is_kr = re.compile('[^ê°€-í£]')
is_en = re.compile('[-a-zA-Z]')
is_num = re.compile('[0-9]')

verb_dic = {}
for i in all_list:
  verb_dic[i]=[]

for ii in v_list:
  try:
    first_ii = j2hcj(h2j(ii))[0]
    verb_dic[first_ii].append(ii)
  except:
    continue